{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db5ae633",
   "metadata": {},
   "source": [
    "# üìä Multi-Source Data Aggregation for Market Context Modeling\n",
    "\n",
    "This notebook builds a consolidated pipeline for collecting and merging:\n",
    "\n",
    "- **Market data** from Yahoo Finance  \n",
    "- **Macroeconomic indicators** from the FRED API  \n",
    "- **Sentiment signals** from Google Trends  \n",
    "\n",
    "These sources power downstream analysis and modeling for the Pendle project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832651d7",
   "metadata": {},
   "source": [
    "## üì¶ Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "769723d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath(\"../scripts\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7777c8c3",
   "metadata": {},
   "source": [
    "## üìà Market Data: Yahoo Finance\n",
    "\n",
    "Daily OHLCV data for:\n",
    "- `^GSPC`, `^IXIC`, `^VIX`, `BTC-USD`  \n",
    "üìÅ Output: `../data/raw/yahoo_market_data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56ef7c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Yahoo Finance Date Range: 2000-01-03 00:00:00 ‚Üí 2025-04-14 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open_^GSPC</th>\n",
       "      <th>High_^GSPC</th>\n",
       "      <th>Low_^GSPC</th>\n",
       "      <th>Close_^GSPC</th>\n",
       "      <th>Adj Close_^GSPC</th>\n",
       "      <th>Volume_^GSPC</th>\n",
       "      <th>Open_BTC-USD</th>\n",
       "      <th>High_BTC-USD</th>\n",
       "      <th>Low_BTC-USD</th>\n",
       "      <th>Close_BTC-USD</th>\n",
       "      <th>...</th>\n",
       "      <th>Low_^VIX</th>\n",
       "      <th>Close_^VIX</th>\n",
       "      <th>Adj Close_^VIX</th>\n",
       "      <th>Volume_^VIX</th>\n",
       "      <th>Open_^IXIC</th>\n",
       "      <th>High_^IXIC</th>\n",
       "      <th>Low_^IXIC</th>\n",
       "      <th>Close_^IXIC</th>\n",
       "      <th>Adj Close_^IXIC</th>\n",
       "      <th>Volume_^IXIC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>1469.250000</td>\n",
       "      <td>1478.000000</td>\n",
       "      <td>1438.359985</td>\n",
       "      <td>1455.219971</td>\n",
       "      <td>1455.219971</td>\n",
       "      <td>9.318000e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>23.980000</td>\n",
       "      <td>24.209999</td>\n",
       "      <td>24.209999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4186.189941</td>\n",
       "      <td>4192.189941</td>\n",
       "      <td>3989.709961</td>\n",
       "      <td>4131.149902</td>\n",
       "      <td>4131.149902</td>\n",
       "      <td>1.510070e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>1455.219971</td>\n",
       "      <td>1455.219971</td>\n",
       "      <td>1397.430054</td>\n",
       "      <td>1399.420044</td>\n",
       "      <td>1399.420044</td>\n",
       "      <td>1.009000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>24.799999</td>\n",
       "      <td>27.010000</td>\n",
       "      <td>27.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4020.000000</td>\n",
       "      <td>4073.250000</td>\n",
       "      <td>3898.229980</td>\n",
       "      <td>3901.689941</td>\n",
       "      <td>3901.689941</td>\n",
       "      <td>1.511840e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>1399.420044</td>\n",
       "      <td>1413.270020</td>\n",
       "      <td>1377.680054</td>\n",
       "      <td>1402.109985</td>\n",
       "      <td>1402.109985</td>\n",
       "      <td>1.085500e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25.850000</td>\n",
       "      <td>26.410000</td>\n",
       "      <td>26.410000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3854.350098</td>\n",
       "      <td>3924.209961</td>\n",
       "      <td>3734.870117</td>\n",
       "      <td>3877.540039</td>\n",
       "      <td>3877.540039</td>\n",
       "      <td>1.735670e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>1402.109985</td>\n",
       "      <td>1411.900024</td>\n",
       "      <td>1392.099976</td>\n",
       "      <td>1403.449951</td>\n",
       "      <td>1403.449951</td>\n",
       "      <td>1.092300e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>25.730000</td>\n",
       "      <td>25.730000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3834.439941</td>\n",
       "      <td>3868.760010</td>\n",
       "      <td>3715.620117</td>\n",
       "      <td>3727.129883</td>\n",
       "      <td>3727.129883</td>\n",
       "      <td>1.598320e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>1403.449951</td>\n",
       "      <td>1441.469971</td>\n",
       "      <td>1400.729980</td>\n",
       "      <td>1441.469971</td>\n",
       "      <td>1441.469971</td>\n",
       "      <td>1.225200e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>21.719999</td>\n",
       "      <td>21.719999</td>\n",
       "      <td>21.719999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3711.090088</td>\n",
       "      <td>3882.669922</td>\n",
       "      <td>3711.090088</td>\n",
       "      <td>3882.620117</td>\n",
       "      <td>3882.620117</td>\n",
       "      <td>1.634930e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open_^GSPC   High_^GSPC    Low_^GSPC  Close_^GSPC  \\\n",
       "Date                                                             \n",
       "2000-01-03  1469.250000  1478.000000  1438.359985  1455.219971   \n",
       "2000-01-04  1455.219971  1455.219971  1397.430054  1399.420044   \n",
       "2000-01-05  1399.420044  1413.270020  1377.680054  1402.109985   \n",
       "2000-01-06  1402.109985  1411.900024  1392.099976  1403.449951   \n",
       "2000-01-07  1403.449951  1441.469971  1400.729980  1441.469971   \n",
       "\n",
       "            Adj Close_^GSPC  Volume_^GSPC  Open_BTC-USD  High_BTC-USD  \\\n",
       "Date                                                                    \n",
       "2000-01-03      1455.219971  9.318000e+08           NaN           NaN   \n",
       "2000-01-04      1399.420044  1.009000e+09           NaN           NaN   \n",
       "2000-01-05      1402.109985  1.085500e+09           NaN           NaN   \n",
       "2000-01-06      1403.449951  1.092300e+09           NaN           NaN   \n",
       "2000-01-07      1441.469971  1.225200e+09           NaN           NaN   \n",
       "\n",
       "            Low_BTC-USD  Close_BTC-USD  ...   Low_^VIX  Close_^VIX  \\\n",
       "Date                                    ...                          \n",
       "2000-01-03          NaN            NaN  ...  23.980000   24.209999   \n",
       "2000-01-04          NaN            NaN  ...  24.799999   27.010000   \n",
       "2000-01-05          NaN            NaN  ...  25.850000   26.410000   \n",
       "2000-01-06          NaN            NaN  ...  24.700001   25.730000   \n",
       "2000-01-07          NaN            NaN  ...  21.719999   21.719999   \n",
       "\n",
       "            Adj Close_^VIX  Volume_^VIX   Open_^IXIC   High_^IXIC  \\\n",
       "Date                                                                \n",
       "2000-01-03       24.209999          0.0  4186.189941  4192.189941   \n",
       "2000-01-04       27.010000          0.0  4020.000000  4073.250000   \n",
       "2000-01-05       26.410000          0.0  3854.350098  3924.209961   \n",
       "2000-01-06       25.730000          0.0  3834.439941  3868.760010   \n",
       "2000-01-07       21.719999          0.0  3711.090088  3882.669922   \n",
       "\n",
       "              Low_^IXIC  Close_^IXIC  Adj Close_^IXIC  Volume_^IXIC  \n",
       "Date                                                                 \n",
       "2000-01-03  3989.709961  4131.149902      4131.149902  1.510070e+09  \n",
       "2000-01-04  3898.229980  3901.689941      3901.689941  1.511840e+09  \n",
       "2000-01-05  3734.870117  3877.540039      3877.540039  1.735670e+09  \n",
       "2000-01-06  3715.620117  3727.129883      3727.129883  1.598320e+09  \n",
       "2000-01-07  3711.090088  3882.620117      3882.620117  1.634930e+09  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fetch_yahoo import fetch_market_data\n",
    "\n",
    "# ‚ö†Ô∏è UNCOMMENT TO RUN ONCE\n",
    "# market_df = fetch_market_data(start=\"2000-01-01\", save_path=\"../data/raw/yahoo_market_data.csv\")\n",
    "\n",
    "# ‚úÖ Load from cache\n",
    "market_df = pd.read_csv(\"../data/raw/yahoo_market_data.csv\", index_col=0, parse_dates=True)\n",
    "print(\"üìÖ Yahoo Finance Date Range:\", market_df.index.min(), \"‚Üí\", market_df.index.max())\n",
    "market_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf6361b",
   "metadata": {},
   "source": [
    "## üìä Macroeconomic Indicators: FRED\n",
    "\n",
    "Selected indicators:\n",
    "- Bond Yields (`DGS10`)\n",
    "- Inflation (`CPIAUCSL`)\n",
    "- Unemployment (`UNRATE`)\n",
    "- Interest Rates (`FEDFUNDS`)\n",
    "- Consumer Sentiment (`UMCSENT`)\n",
    "- GDP (`GDP`)  \n",
    "üìÅ Output: `../data/raw/fred_macro_data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2d2d089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ FRED Date Range: 2000-01-03 00:00:00 ‚Üí 2025-04-14 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bond Yields</th>\n",
       "      <th>Inflation</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Interest Rate</th>\n",
       "      <th>Consumer Sentiment</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>6.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>6.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>6.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>6.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>6.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Bond Yields  Inflation  Unemployment  Interest Rate  \\\n",
       "2000-01-03         6.58        NaN           NaN            NaN   \n",
       "2000-01-04         6.49        NaN           NaN            NaN   \n",
       "2000-01-05         6.62        NaN           NaN            NaN   \n",
       "2000-01-06         6.57        NaN           NaN            NaN   \n",
       "2000-01-07         6.52        NaN           NaN            NaN   \n",
       "\n",
       "            Consumer Sentiment  GDP  \n",
       "2000-01-03                 NaN  NaN  \n",
       "2000-01-04                 NaN  NaN  \n",
       "2000-01-05                 NaN  NaN  \n",
       "2000-01-06                 NaN  NaN  \n",
       "2000-01-07                 NaN  NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fetch_fred import fetch_fred_series\n",
    "\n",
    "fred_series = {\n",
    "    \"Bond Yields\": \"DGS10\",\n",
    "    \"Inflation\": \"CPIAUCSL\",\n",
    "    \"Unemployment\": \"UNRATE\",\n",
    "    \"Interest Rate\": \"FEDFUNDS\",\n",
    "    \"Consumer Sentiment\": \"UMCSENT\",\n",
    "    \"GDP\": \"GDP\"\n",
    "}\n",
    "\n",
    "# ‚ö†Ô∏è UNCOMMENT TO RUN ONCE\n",
    "# macro_df = fetch_fred_series(fred_series, start=\"2000-01-01\", save_path=\"../data/raw/fred_macro_data.csv\")\n",
    "\n",
    "# ‚úÖ Load from cache\n",
    "macro_df = pd.read_csv(\"../data/raw/fred_macro_data.csv\", index_col=0, parse_dates=True)\n",
    "print(\"üìÖ FRED Date Range:\", macro_df.index.min(), \"‚Üí\", macro_df.index.max())\n",
    "macro_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d1acb4",
   "metadata": {},
   "source": [
    "## üß† Sentiment Signals: Google Trends\n",
    "\n",
    "Terms:\n",
    "- `\"market crash\"`, `\"recession\"`, `\"buy gold\"`, `\"stock market crash\"`  \n",
    "üìÅ Output: Chunked into 5 raw files ‚Üí merged to `../data/processed/google_trends_full.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cc2501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fetch_sentiment import fetch_google_trends_by_year\n",
    "import json\n",
    "\n",
    "terms = [\"market crash\", \"recession\", \"buy gold\", \"stock market crash\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a929578-e4ed-4e29-b494-29375acb108e",
   "metadata": {},
   "source": [
    "### üîÑ Chunked Pulls (UNCOMMENT to fetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db11fd7-5a31-4643-8043-98146fbd9536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Run Google Trends Sentiment Pull ‚Äî Chunk 1 (2004‚Äì2007)\n",
    "# This function slices each keyword by **year** to allow daily-resolution pulls\n",
    "# while staying under Google‚Äôs rate limits. It is deliberately slow and cautious.\n",
    "\n",
    "# üß† Sentiment-related search terms\n",
    "# - \"market crash\", \"recession\", \"buy gold\", \"stock market crash\"\n",
    "# - These represent fear/flight-to-safety behaviors in investor psychology.\n",
    "\n",
    "# ‚ö†Ô∏è UNCOMMENT TO DEPLOY THIS MISSION ONLY ONCE ‚Äî pulls daily resolution by year\n",
    "# Chunk 1: 2004‚Äì2007\n",
    "# Pulls Google Trends data in ultra-safe mode ‚Äî by keyword, by year ‚Äî with max stealth cooldowns\n",
    "# Useful for behavioral signals like fear, recession concern, and flight-to-safety instincts\n",
    "sentiment_df_1 = fetch_google_trends_by_year(\n",
    "    keywords=terms,                                       # üéØ Target terms: market panic + hedge signals\n",
    "    start_year=2004,                                      # üóìÔ∏è Start of available Google Trends data\n",
    "    end_year=2007,                                        # ‚è≥ Cutoff for this batch\n",
    "    save_path=\"../data/raw/google_trends_2004_2007.csv\",  # üíæ Drop point for raw intel\n",
    "    batch_size=1,                                         # üö® Solo keyword pulls ‚Äî avoid 400 Bad Requests\n",
    "    cooldown=74                                           # üßä MAX STEALTH: long sleep to dodge throttling (429 errors)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee9e8eee-c950-458c-b928-db570b7e77df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Fetching Google Trends data (daily granularity) for: ['market crash', 'recession', 'buy gold', 'stock market crash']\n",
      "üîÅ Year 2008, Batch 1: ['market crash']\n",
      "üîÅ Year 2008, Batch 2: ['recession']\n",
      "‚ùå Error fetching ['recession'] for 2008: HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /trends/api/explore?hl=en-US&tz=360&req=%7B%22comparisonItem%22%3A+%5B%7B%22keyword%22%3A+%22recession%22%2C+%22time%22%3A+%222008-01-01+2008-12-31%22%2C+%22geo%22%3A+%22US%22%7D%5D%2C+%22category%22%3A+0%2C+%22property%22%3A+%22%22%7D (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x1472fe9d0>, 'Connection to trends.google.com timed out. (connect timeout=2)'))\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2008, Batch 3: ['buy gold']\n",
      "üîÅ Year 2008, Batch 4: ['stock market crash']\n",
      "‚ùå Error fetching ['stock market crash'] for 2008: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2009, Batch 1: ['market crash']\n",
      "üîÅ Year 2009, Batch 2: ['recession']\n",
      "üîÅ Year 2009, Batch 3: ['buy gold']\n",
      "üîÅ Year 2009, Batch 4: ['stock market crash']\n",
      "üîÅ Year 2010, Batch 1: ['market crash']\n",
      "üîÅ Year 2010, Batch 2: ['recession']\n",
      "üîÅ Year 2010, Batch 3: ['buy gold']\n",
      "üîÅ Year 2010, Batch 4: ['stock market crash']\n",
      "üîÅ Year 2011, Batch 1: ['market crash']\n",
      "‚ùå Error fetching ['market crash'] for 2011: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2011, Batch 2: ['recession']\n",
      "‚ùå Error fetching ['recession'] for 2011: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2011, Batch 3: ['buy gold']\n",
      "‚ùå Error fetching ['buy gold'] for 2011: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2011, Batch 4: ['stock market crash']\n",
      "‚ùå Error fetching ['stock market crash'] for 2011: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "‚úÖ Saved Google Trends data to ../data/raw/google_trends_2008_2011.csv\n"
     ]
    }
   ],
   "source": [
    "# Chunk 2: 2008‚Äì2011\n",
    "sentiment_df_2 = fetch_google_trends_by_year(\n",
    "    keywords=terms,\n",
    "    start_year=2008,\n",
    "    end_year=2011,\n",
    "    save_path=\"../data/raw/google_trends_2008_2011.csv\",\n",
    "    batch_size=1,\n",
    "    cooldown=74\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "448b2479-3c1a-480d-9733-634dd772ec3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Fetching Google Trends data (daily granularity) for: ['market crash', 'recession', 'buy gold', 'stock market crash']\n",
      "üîÅ Year 2012, Batch 1: ['market crash']\n",
      "‚ùå Error fetching ['market crash'] for 2012: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2012, Batch 2: ['recession']\n",
      "‚ùå Error fetching ['recession'] for 2012: HTTPSConnectionPool(host='trends.google.com', port=443): Read timed out. (read timeout=5)\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2012, Batch 3: ['buy gold']\n",
      "‚ùå Error fetching ['buy gold'] for 2012: HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /trends/api/explore?hl=en-US&tz=360&req=%7B%22comparisonItem%22%3A+%5B%7B%22keyword%22%3A+%22buy+gold%22%2C+%22time%22%3A+%222012-01-01+2012-12-31%22%2C+%22geo%22%3A+%22US%22%7D%5D%2C+%22category%22%3A+0%2C+%22property%22%3A+%22%22%7D (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x14ea85fd0>, 'Connection to trends.google.com timed out. (connect timeout=2)'))\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2012, Batch 4: ['stock market crash']\n",
      "üîÅ Year 2013, Batch 1: ['market crash']\n",
      "‚ùå Error fetching ['market crash'] for 2013: HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /trends/api/explore?hl=en-US&tz=360&req=%7B%22comparisonItem%22%3A+%5B%7B%22keyword%22%3A+%22market+crash%22%2C+%22time%22%3A+%222013-01-01+2013-12-31%22%2C+%22geo%22%3A+%22US%22%7D%5D%2C+%22category%22%3A+0%2C+%22property%22%3A+%22%22%7D (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x14ead7a10>, 'Connection to trends.google.com timed out. (connect timeout=2)'))\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2013, Batch 2: ['recession']\n",
      "‚ùå Error fetching ['recession'] for 2013: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2013, Batch 3: ['buy gold']\n",
      "‚ùå Error fetching ['buy gold'] for 2013: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2013, Batch 4: ['stock market crash']\n",
      "‚ùå Error fetching ['stock market crash'] for 2013: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2014, Batch 1: ['market crash']\n",
      "‚ùå Error fetching ['market crash'] for 2014: HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /trends/api/explore?hl=en-US&tz=360&req=%7B%22comparisonItem%22%3A+%5B%7B%22keyword%22%3A+%22market+crash%22%2C+%22time%22%3A+%222014-01-01+2014-12-31%22%2C+%22geo%22%3A+%22US%22%7D%5D%2C+%22category%22%3A+0%2C+%22property%22%3A+%22%22%7D (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x14eade450>, 'Connection to trends.google.com timed out. (connect timeout=2)'))\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2014, Batch 2: ['recession']\n",
      "‚ùå Error fetching ['recession'] for 2014: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2014, Batch 3: ['buy gold']\n",
      "‚ùå Error fetching ['buy gold'] for 2014: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2014, Batch 4: ['stock market crash']\n",
      "‚ùå Error fetching ['stock market crash'] for 2014: HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /trends/api/explore?hl=en-US&tz=360&req=%7B%22comparisonItem%22%3A+%5B%7B%22keyword%22%3A+%22stock+market+crash%22%2C+%22time%22%3A+%222014-01-01+2014-12-31%22%2C+%22geo%22%3A+%22US%22%7D%5D%2C+%22category%22%3A+0%2C+%22property%22%3A+%22%22%7D (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x14ea3b550>, 'Connection to trends.google.com timed out. (connect timeout=2)'))\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2015, Batch 1: ['market crash']\n",
      "‚ùå Error fetching ['market crash'] for 2015: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2015, Batch 2: ['recession']\n",
      "‚ùå Error fetching ['recession'] for 2015: HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /trends/api/explore?hl=en-US&tz=360&req=%7B%22comparisonItem%22%3A+%5B%7B%22keyword%22%3A+%22recession%22%2C+%22time%22%3A+%222015-01-01+2015-12-31%22%2C+%22geo%22%3A+%22US%22%7D%5D%2C+%22category%22%3A+0%2C+%22property%22%3A+%22%22%7D (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x14ea7c550>, 'Connection to trends.google.com timed out. (connect timeout=2)'))\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2015, Batch 3: ['buy gold']\n",
      "‚ùå Error fetching ['buy gold'] for 2015: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2015, Batch 4: ['stock market crash']\n",
      "‚ùå Error fetching ['stock market crash'] for 2015: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "‚úÖ Saved Google Trends data to ../data/raw/google_trends_2012_2015.csv\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# üïµÔ∏è Sentiment Reconnaissance: Chunk 3 (2012‚Äì2015)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Pulls Google Trends data in max stealth mode ‚Äî daily resolution, 1 keyword at a time.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Saves any failed (keyword, year) pairs to a .json file for retry later.\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m sentiment_df_3, failures_3 \u001b[38;5;241m=\u001b[39m fetch_google_trends_by_year(\n\u001b[1;32m      6\u001b[0m     keywords\u001b[38;5;241m=\u001b[39mterms,\n\u001b[1;32m      7\u001b[0m     start_year\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2012\u001b[39m,\n\u001b[1;32m      8\u001b[0m     end_year\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2015\u001b[39m,\n\u001b[1;32m      9\u001b[0m     save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/raw/google_trends_2012_2015.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     11\u001b[0m     cooldown\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# üíæ Save failed (keyword, year) pairs for retry\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../logs/failures_2012_2015.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# üïµÔ∏è Sentiment Reconnaissance: Chunk 3 (2012‚Äì2015)\n",
    "# Pulls Google Trends data in max stealth mode ‚Äî daily resolution, 1 keyword at a time.\n",
    "# Saves any failed (keyword, year) pairs to a .json file for retry later.\n",
    "\n",
    "sentiment_df_3, failures_3 = fetch_google_trends_by_year(\n",
    "    keywords=terms,\n",
    "    start_year=2012,\n",
    "    end_year=2015,\n",
    "    save_path=\"../data/raw/google_trends_2012_2015.csv\",\n",
    "    batch_size=1,\n",
    "    cooldown=6\n",
    ")\n",
    "\n",
    "# üíæ Save failed (keyword, year) pairs for retry\n",
    "with open(\"../logs/failures_2012_2015.json\", \"w\") as f:\n",
    "    json.dump(failures_3, f)\n",
    "\n",
    "print(\"üì¶ Saved Chunk 3\")\n",
    "print(\"üßØ Failed fetch attempts:\", failures_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c5db93d-f7b9-46f2-abda-446cf51c3a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Fetching Google Trends data (daily granularity) for: ['market crash', 'recession', 'buy gold', 'stock market crash']\n",
      "üîÅ Year 2016, Batch 1: ['market crash']\n",
      "‚ùå Error fetching ['market crash'] for 2016: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2016, Batch 2: ['recession']\n",
      "‚ùå Error fetching ['recession'] for 2016: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2016, Batch 3: ['buy gold']\n",
      "‚ùå Error fetching ['buy gold'] for 2016: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2016, Batch 4: ['stock market crash']\n",
      "‚ùå Error fetching ['stock market crash'] for 2016: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2017, Batch 1: ['market crash']\n",
      "‚ùå Error fetching ['market crash'] for 2017: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2017, Batch 2: ['recession']\n",
      "‚ùå Error fetching ['recession'] for 2017: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2017, Batch 3: ['buy gold']\n",
      "‚ùå Error fetching ['buy gold'] for 2017: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2017, Batch 4: ['stock market crash']\n",
      "‚ùå Error fetching ['stock market crash'] for 2017: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2018, Batch 1: ['market crash']\n",
      "‚ùå Error fetching ['market crash'] for 2018: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2018, Batch 2: ['recession']\n",
      "‚ùå Error fetching ['recession'] for 2018: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2018, Batch 3: ['buy gold']\n",
      "‚ùå Error fetching ['buy gold'] for 2018: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2018, Batch 4: ['stock market crash']\n",
      "‚ùå Error fetching ['stock market crash'] for 2018: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2019, Batch 1: ['market crash']\n",
      "üîÅ Year 2019, Batch 2: ['recession']\n",
      "‚ùå Error fetching ['recession'] for 2019: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2019, Batch 3: ['buy gold']\n",
      "‚ùå Error fetching ['buy gold'] for 2019: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2019, Batch 4: ['stock market crash']\n",
      "‚ùå Error fetching ['stock market crash'] for 2019: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "‚úÖ Saved Google Trends data to ../data/raw/google_trends_2016_2019.csv\n"
     ]
    }
   ],
   "source": [
    "# Chunk 4: 2016‚Äì2019\n",
    "sentiment_df_4 = fetch_google_trends_by_year(\n",
    "    keywords=terms,\n",
    "    start_year=2016,\n",
    "    end_year=2019,\n",
    "    save_path=\"../data/raw/google_trends_2016_2019.csv\",\n",
    "    batch_size=1,\n",
    "    cooldown=74\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0a45a3-d475-4a1f-8eb3-652e5ed4056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk 5: 2020‚Äì2025\n",
    "sentiment_df_5 = fetch_google_trends_by_year(\n",
    "    keywords=terms,\n",
    "    start_year=2020,\n",
    "    end_year=2025,\n",
    "    save_path=\"../data/raw/google_trends_2020_2025.csv\",\n",
    "    batch_size=1,\n",
    "    cooldown=74\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6578ea-2774-4a0a-9902-ebbcbd2a2208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e7d32c-ab3c-426d-8fcf-45bfa4978f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù Define missing keyword-year pairs manually\n",
    "failures_1 = [\n",
    "    (\"recession\", 2006)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c3efd-9765-4099-be4e-c9f6668632c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009f47b3-4dba-4468-b802-0e00731eae90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07af9531-1bc7-4925-8e34-57beb005d9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7930ed5d-02d6-43e9-a3ec-7a61b68b6315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ccb8ce3-1bcc-4399-893e-7b1e9dd222d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Fetching Google Trends data (daily granularity) for: ['market crash', 'recession', 'buy gold', 'stock market crash']\n",
      "üîÅ Year 2004, Batch 1: ['market crash']\n",
      "üîÅ Year 2004, Batch 2: ['recession']\n",
      "üîÅ Year 2004, Batch 3: ['buy gold']\n",
      "üîÅ Year 2004, Batch 4: ['stock market crash']\n",
      "üîÅ Year 2005, Batch 1: ['market crash']\n",
      "üîÅ Year 2005, Batch 2: ['recession']\n",
      "üîÅ Year 2005, Batch 3: ['buy gold']\n",
      "üîÅ Year 2005, Batch 4: ['stock market crash']\n",
      "üîÅ Year 2006, Batch 1: ['market crash']\n",
      "üîÅ Year 2006, Batch 2: ['recession']\n",
      "‚ùå Error fetching ['recession'] for 2006: The request failed: Google returned a response with code 429\n",
      "‚è≥ Cooling down before retrying...\n",
      "üîÅ Year 2006, Batch 3: ['buy gold']\n",
      "üîÅ Year 2006, Batch 4: ['stock market crash']\n",
      "üîÅ Year 2007, Batch 1: ['market crash']\n",
      "üîÅ Year 2007, Batch 2: ['recession']\n",
      "üîÅ Year 2007, Batch 3: ['buy gold']\n",
      "üîÅ Year 2007, Batch 4: ['stock market crash']\n",
      "‚úÖ Saved Google Trends data to ../data/raw/google_trends_2004_2007.csv\n"
     ]
    }
   ],
   "source": [
    "sentiment_df_1 = fetch_google_trends_by_year(\n",
    "    keywords=terms,                                       # ‚úÖ Your list of search terms\n",
    "    start_year=2004,                                      # ‚úÖ First year to pull\n",
    "    end_year=2007,                                        # ‚úÖ Last year to pull\n",
    "    save_path=\"../data/raw/google_trends_2004_2007.csv\",  # ‚úÖ Output location\n",
    "    batch_size=1,                                         # ‚úÖ Pull one keyword at a time to prevent 400s\n",
    "    cooldown=74                                           # ‚úÖ Sleep to avoid throttling, ultra-conservative max stealth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f538fee-5149-44f6-a97e-c5a5fbdcdba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_df_2 = fetch_google_trends_by_year(terms, 2008, 2011, \"../data/raw/google_trends_2008_2011.csv\", 1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0376f078-93fe-4a43-87b0-63eb7c793aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_df_3 = fetch_google_trends_by_year(terms, 2012, 2015, \"../data/raw/google_trends_2012_2015.csv\", 1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ad686-c3fe-4912-9dfa-105623110220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_df_4 = fetch_google_trends_by_year(terms, 2016, 2019, \"../data/raw/google_trends_2016_2019.csv\", 1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f6b9a-7df6-4cbd-9225-2ef3e4b9f7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_df_5 = fetch_google_trends_by_year(terms, 2020, 2025, \"../data/raw/google_trends_2020_2025.csv\", 1, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579755c3",
   "metadata": {},
   "source": [
    "### ‚úÖ Load and Merge Sentiment Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bf19b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Trends Chunk 2004_2007: nan ‚Üí nan\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/raw/google_trends_2008_2011.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m span \u001b[38;5;129;01min\u001b[39;00m sentiment_chunks:\n\u001b[0;32m----> 5\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/raw/google_trends_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspan\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, parse_dates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìÖ Trends Chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspan\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mmin(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚Üí\u001b[39m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mmax())\n\u001b[1;32m      7\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(df)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/raw/google_trends_2008_2011.csv'"
     ]
    }
   ],
   "source": [
    "sentiment_chunks = [\"2004_2007\", \"2008_2011\", \"2012_2015\", \"2016_2019\", \"2020_2025\"]\n",
    "\n",
    "dfs = []\n",
    "for span in sentiment_chunks:\n",
    "    df = pd.read_csv(f\"../data/raw/google_trends_{span}.csv\", index_col=0, parse_dates=True)\n",
    "    print(f\"üìÖ Trends Chunk {span}:\", df.index.min(), \"‚Üí\", df.index.max())\n",
    "    dfs.append(df)\n",
    "\n",
    "sentiment_df = pd.concat(dfs).sort_index()\n",
    "sentiment_df.to_csv(\"../data/processed/google_trends_full.csv\")\n",
    "print(\"‚úÖ Final merged sentiment dataset saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6efbbc",
   "metadata": {},
   "source": [
    "## üì¶ Final Merge: Market + Macro + Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8842be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• Load all cleaned datasets\n",
    "market_df = pd.read_csv(\"../data/raw/yahoo_market_data.csv\", index_col=0, parse_dates=True)\n",
    "macro_df = pd.read_csv(\"../data/raw/fred_macro_data.csv\", index_col=0, parse_dates=True)\n",
    "sentiment_df = pd.read_csv(\"../data/processed/google_trends_full.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "# üîó Merge all sources\n",
    "merged = market_df.join(macro_df, how=\"outer\").join(sentiment_df, how=\"outer\")\n",
    "merged = merged.sort_index()\n",
    "\n",
    "# üíæ Save full merged dataset\n",
    "merged.to_csv(\"../data/processed/merged_all_sources.csv\")\n",
    "\n",
    "# üëÄ Preview merged output\n",
    "print(\"üìä Final Merged Dataset:\")\n",
    "print(\"Date Range:\", merged.index.min(), \"‚Üí\", merged.index.max())\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf1abae",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "We successfully built a modular and interpretable ingestion pipeline for:\n",
    "\n",
    "- ‚úÖ Daily market data (`yfinance`)\n",
    "- ‚úÖ Macroeconomic indicators (`FRED`)\n",
    "- ‚úÖ Sentiment trends (`Google Trends` via `pytrends`)\n",
    "\n",
    "üìÅ All data has been cached, aligned, and merged into a single file:\n",
    "```\n",
    "../data/processed/merged_all_sources.csv\n",
    "```\n",
    "\n",
    "Next steps: **EDA, lag feature engineering, and predictive modeling.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
